# ğŸ¤– Document QA Service (Local RAG)

FastAPI + FAISS + SentenceTransformer + Ollama ile Ã§alÄ±ÅŸan yerel dokÃ¼man soru-cevap servisi.

## ğŸ“‹ Ä°Ã§indekiler

- [Ã–zellikler](#-Ã¶zellikler)
- [Gereksinimler](#-gereksinimler)
- [Kurulum](#-kurulum)
- [KullanÄ±m](#-kullanÄ±m)
- [API DokÃ¼mantasyonu](#-api-dokÃ¼mantasyonu)
- [Proje YapÄ±sÄ±](#-proje-yapÄ±sÄ±)
- [YapÄ±landÄ±rma](#-yapÄ±landÄ±rma)

## âœ¨ Ã–zellikler

- **Yerel LLM DesteÄŸi**: Ollama kullanarak tamamen yerel Ã§alÄ±ÅŸÄ±r, internet gerektirmez
- **RAG (Retrieval Augmented Generation)**: DokÃ¼manlarÄ±nÄ±zÄ± analiz eder ve baÄŸlamsal cevaplar Ã¼retir
- **Ä°ki Mod**: 
  - **Fast Mode**: KÃ¼Ã§Ã¼k dokÃ¼manlar iÃ§in hÄ±zlÄ± iÅŸlem (max 3200 karakter)
  - **Long Mode**: BÃ¼yÃ¼k dokÃ¼manlar iÃ§in kapsamlÄ± analiz (max 50000 karakter)
- **FAISS VektÃ¶r Arama**: HÄ±zlÄ± ve verimli semantik arama
- **Streamlit Web ArayÃ¼zÃ¼**: KullanÄ±cÄ± dostu interaktif arayÃ¼z
- **RESTful API**: FastAPI ile gÃ¼Ã§lÃ¼ ve hÄ±zlÄ± API

## ğŸ”§ Gereksinimler

### Sistem Gereksinimleri
- Python 3.9 veya Ã¼zeri
- Node.js 16+ (docx oluÅŸturma iÃ§in, opsiyonel)
- En az 4GB RAM
- 2GB boÅŸ disk alanÄ±

### Ollama Kurulumu
Bu proje Ollama kullandÄ±ÄŸÄ± iÃ§in Ã¶nce Ollama'yÄ± kurmanÄ±z gerekiyor:

1. [Ollama.ai](https://ollama.ai) adresinden Ollama'yÄ± indirin ve kurun
2. Terminalde ÅŸu komutu Ã§alÄ±ÅŸtÄ±rarak modeli indirin:
```bash
ollama pull llama3
```

3. Ollama'nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol edin:
```bash
ollama list
```

## ğŸš€ Kurulum

### 1. Projeyi Ä°ndirin
```bash
unzip document-qa-service.zip
cd document-qa-service
```

### 2. Sanal Ortam OluÅŸturun
**Linux/Mac:**
```bash
python3 -m venv venv
source venv/bin/activate
```

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

### 3. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

Gerekli paketler:
- `fastapi` - Web framework
- `uvicorn` - ASGI server
- `pydantic` - Veri validasyonu
- `sentence-transformers` - Embedding model
- `faiss-cpu` - VektÃ¶r arama
- `requests` - HTTP istekleri
- `streamlit` - Web arayÃ¼zÃ¼
- `python-multipart` - Dosya upload
- `Pillow` - GÃ¶rsel iÅŸleme

### 4. Proje YapÄ±sÄ±nÄ± OluÅŸturun (Ä°lk Kurulum)
EÄŸer klasÃ¶r yapÄ±sÄ± eksikse:
```bash
python setup_project.py
```

## ğŸ’» KullanÄ±m

### Backend API'yi BaÅŸlatma

```bash
python run.py
```

Servis baÅŸladÄ±ÄŸÄ±nda ÅŸu bilgileri gÃ¶receksiniz:
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Document QA Service v1.0.0
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ Servis baÅŸlatÄ±lÄ±yor...
ğŸ“ Bind Host: 0.0.0.0:8000
ğŸŒ Local URL: http://localhost:8000
ğŸ¤– LLM Model: llama3
ğŸ“š VektÃ¶r DB: FAISS

ğŸ“– API DokÃ¼mantasyonu:
   - Swagger UI: http://localhost:8000/api/v1/docs
   - ReDoc:      http://localhost:8000/api/v1/redoc
```

### Frontend ArayÃ¼zÃ¼ (Streamlit)

Yeni bir terminal aÃ§Ä±n ve:
```bash
streamlit run frontend/app.py
```

TarayÄ±cÄ±nÄ±zda otomatik olarak `http://localhost:8501` aÃ§Ä±lacaktÄ±r.

## ğŸ“– API DokÃ¼mantasyonu

### Endpoints

#### 1. DokÃ¼man YÃ¼kleme
**POST** `/api/v1/upload`

Bir TXT dosyasÄ± yÃ¼kler ve index oluÅŸturur.

**Parametreler:**
- `mode` (query): `"fast"` veya `"long"` (default: `"fast"`)
- `file` (form): TXT dosyasÄ±

**Ã–rnek:**
```bash
curl -X POST "http://localhost:8000/api/v1/upload?mode=fast" \
  -F "file=@mydocument.txt"
```

**YanÄ±t:**
```json
{
  "doc_id": "a1b2c3d4-5678-90ef-ghij-klmnopqrstuv",
  "mode": "fast",
  "chars": 1542,
  "chunks": 4
}
```

#### 2. Soru Sorma
**POST** `/api/v1/ask`

YÃ¼klenen dokÃ¼mana soru sorar.

**Ä°stek Body:**
```json
{
  "doc_id": "a1b2c3d4-5678-90ef-ghij-klmnopqrstuv",
  "question": "Git version control nedir?",
  "top_k": 3
}
```

**YanÄ±t:**
```json
{
  "question": "Git version control nedir?",
  "answer": "Git, yazÄ±lÄ±m projelerinde kod deÄŸiÅŸikliklerini takip eden...",
  "sources": [
    {
      "file": "user_upload",
      "chunk": "Git bir versiyon kontrol sistemidir...",
      "relevance": 0.89
    }
  ],
  "confidence": "high"
}
```

#### 3. SaÄŸlÄ±k KontrolÃ¼
**GET** `/`

Servisin durumunu kontrol eder.

**YanÄ±t:**
```json
{
  "service": "Document QA Service",
  "version": "1.0.0",
  "status": "running",
  "docs": "/api/v1/docs"
}
```

## ğŸ“ Proje YapÄ±sÄ±

```
document-qa-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py           # Paket baÅŸlatÄ±cÄ±
â”‚   â”œâ”€â”€ main.py               # FastAPI uygulamasÄ±
â”‚   â”œâ”€â”€ config.py             # YapÄ±landÄ±rma ayarlarÄ±
â”‚   â”œâ”€â”€ deps.py               # Dependency injection
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py         # API endpoint'leri
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py        # Pydantic modelleri
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag_service.py    # RAG servisi
â”‚   â”‚   â”œâ”€â”€ llm_service.py    # Ollama LLM servisi
â”‚   â”‚   â”œâ”€â”€ document_service.py  # DokÃ¼man iÅŸleme
â”‚   â”‚   â””â”€â”€ buddy_store.py    # In-memory veri store
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py                # Streamlit arayÃ¼zÃ¼
â”‚   â””â”€â”€ assets/
â”‚       â””â”€â”€ company_logo.jpg  # Logo (opsiyonel)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/            # DokÃ¼manlar (opsiyonel)
â”‚   â””â”€â”€ vectordb/             # VektÃ¶r DB (opsiyonel)
â”œâ”€â”€ run.py                    # Uygulama baÅŸlatÄ±cÄ±
â”œâ”€â”€ setup_project.py          # KlasÃ¶r yapÄ±sÄ± oluÅŸturucu
â”œâ”€â”€ requirements.txt          # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â””â”€â”€ README.md                 # Bu dosya
```

## âš™ï¸ YapÄ±landÄ±rma

### Ortam DeÄŸiÅŸkenleri


```env
# Uygulama
APP_NAME=Document QA Service
APP_VERSION=1.0.0
DEBUG=false

# API
API_HOST=0.0.0.0
API_PORT=8000
API_PREFIX=/api/v1

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3
OLLAMA_TIMEOUT=120

# Embedding
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# RAG
TOP_K_RESULTS=3
MIN_RELEVANCE_SCORE=0.5

# DokÃ¼man Ä°ÅŸleme
CHUNK_SIZE=500
CHUNK_OVERLAP=50
MAX_FILE_SIZE_MB=10
```

### Mod AyarlarÄ±

**Fast Mode** (HÄ±zlÄ± - KÄ±sa DokÃ¼manlar):
- Max karakter: 3200
- Chunk boyutu: 400
- Chunk Ã¶rtÃ¼ÅŸme: 50
- Top-K: 3

**Long Mode** (KapsamlÄ± - Uzun DokÃ¼manlar):
- Max karakter: 50000
- Chunk boyutu: 600
- Chunk Ã¶rtÃ¼ÅŸme: 80
- Top-K: 5

## ğŸ” KullanÄ±m SenaryolarÄ±

### Senaryo 1: Web ArayÃ¼zÃ¼ ile KullanÄ±m

1. Backend'i baÅŸlatÄ±n: `python run.py`
2. Frontend'i baÅŸlatÄ±n: `streamlit run frontend/app.py`
3. TarayÄ±cÄ±da `http://localhost:8501` adresine gidin
4. Bir TXT dosyasÄ± yÃ¼kleyin
5. SorularÄ±nÄ±zÄ± sorun!

### Senaryo 2: API ile KullanÄ±m

```python
import requests

# 1. DokÃ¼man yÃ¼kle
with open("document.txt", "rb") as f:
    response = requests.post(
        "http://localhost:8000/api/v1/upload?mode=fast",
        files={"file": f}
    )
    doc_id = response.json()["doc_id"]

# 2. Soru sor
response = requests.post(
    "http://localhost:8000/api/v1/ask",
    json={
        "doc_id": doc_id,
        "question": "Bu dokÃ¼man ne hakkÄ±nda?",
        "top_k": 3
    }
)
print(response.json()["answer"])
```
